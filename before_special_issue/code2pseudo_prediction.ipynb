{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and variable setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import retrieve_texts, DataObject, data_shapes, token_integer_mapping, prepare_model_data, shape_info\n",
    "from keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "data_dir_train = 'data/train/'                                    # Path to the train data txt files on disk\n",
    "data_dir_test = 'data/test/'                                      # Path to the test data txt files on disk\n",
    "model_path = 'checkpoints/c2p_att_plain_lat3072_b32_iter23.hdf5'  # Path to model checkpoints\n",
    "result_dir = 'results/'\n",
    "num_samples_train = 5001                                          # Number of samples to train on (almost)\n",
    "num_samples_test = 200                                            # Number of samples to test on\n",
    "# Maximum length for inputs and outputs (in terms of characters, not tokens)\n",
    "max_input_length = 1000000                                        # Number of largest acceptibale input length\n",
    "max_target_length = 1800                                          # Number of largest acceptibale target length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training data\n",
    "input_texts, target_texts, input_lists, target_lists, input_tokens, target_tokens = retrieve_texts(data_dir_train, num_samples_train, max_input_length, max_target_length)\n",
    "train_do = DataObject(input_texts, target_texts, input_lists, target_lists, input_tokens, target_tokens)\n",
    "# Data shapes\n",
    "num_encoder_tokens_train, num_decoder_tokens_train, max_encoder_seq_length_train, max_decoder_seq_length_train, n_input_samples_train = data_shapes(train_do)\n",
    "\n",
    "# Get testing data\n",
    "input_texts, target_texts, input_lists, target_lists, input_tokens, target_tokens = retrieve_texts(data_dir_test, num_samples_test, max_input_length, max_target_length)\n",
    "test_do = DataObject(input_texts, target_texts, input_lists, target_lists, input_tokens, target_tokens)\n",
    "# Data shapes\n",
    "num_encoder_tokens_test, num_decoder_tokens_test, max_encoder_seq_length_test, max_decoder_seq_length_test, n_input_samples_test = data_shapes(test_do)\n",
    "\n",
    "# Converting tokens to integers (Neural Networks accept only integers as inputs), and\n",
    "# reverse-lookup token index to decode sequences back to something readable.\n",
    "input_token_index, target_token_index, reverse_input_token_index, reverse_target_token_index = token_integer_mapping(train_do.input_tokens, train_do.target_tokens)\n",
    "\n",
    "# Preprare data for model training\n",
    "encoder_input_data, _, _ = prepare_model_data(test_do.input_lists, test_do.target_lists, input_token_index, target_token_index, n_input_samples_test, max_encoder_seq_length_test, max_decoder_seq_length_test, num_decoder_tokens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data info:-\n",
      "Number of samples: 5000\n",
      "Number of unique input tokens: 4339\n",
      "Number of unique output tokens: 4159\n",
      "Max sequence length for inputs: 527\n",
      "Max sequence length for outputs: 231\n",
      "====================\n",
      "Testing data info:-\n",
      "Number of samples: 200\n",
      "Number of unique input tokens: 431\n",
      "Number of unique output tokens: 547\n",
      "Max sequence length for inputs: 47\n",
      "Max sequence length for outputs: 82\n"
     ]
    }
   ],
   "source": [
    "# Print info\n",
    "print(\"Training data info:-\")\n",
    "shape_info(n_input_samples_train, num_encoder_tokens_train, num_decoder_tokens_train, max_encoder_seq_length_train, max_decoder_seq_length_train)\n",
    "print(\"====================\")\n",
    "print(\"Testing data info:-\")\n",
    "shape_info(n_input_samples_test, num_encoder_tokens_test, num_decoder_tokens_test, max_encoder_seq_length_test, max_decoder_seq_length_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0825 19:35:08.632159 140669728122624 deprecation_wrapper.py:119] From /home/aziz/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0825 19:35:08.649503 140669728122624 deprecation_wrapper.py:119] From /home/aziz/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0825 19:35:08.651515 140669728122624 deprecation_wrapper.py:119] From /home/aziz/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0825 19:35:20.986823 140669728122624 deprecation.py:323] From /home/aziz/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0825 19:35:33.519519 140669728122624 deprecation_wrapper.py:119] From /home/aziz/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0825 19:35:33.520456 140669728122624 deprecation_wrapper.py:119] From /home/aziz/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0825 19:35:46.652465 140669728122624 deprecation_wrapper.py:119] From /home/aziz/anaconda3/envs/tf/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 3072)   13329408    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 3072)   12776448    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 3072), 75509760    embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, None, 3072)   75509760    embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, None, None)   0           lstm_2[0][0]                     \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, None, None)   0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, None, 3072)   0           attention[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 6144)   0           dot_2[0][0]                      \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 3072)   18877440    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 4159)   12780607    dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 208,783,423\n",
      "Trainable params: 208,783,423\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "generator = load_model(model_path)\n",
    "# print(\"model path:\", model_path)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, model, max_decoder_seq_length, target_token_index, reverse_target_token_index):\n",
    "    target_seq = np.zeros(shape=(len(input_seq), max_decoder_seq_length))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[:, 0] = target_token_index[\"<sop>\"]\n",
    "    for i in range(1, max_decoder_seq_length):\n",
    "        prediction = model.predict([input_seq, target_seq]).argmax(axis=2)\n",
    "        ###print(reverse_target_token_index[prediction[:, i][0]])\n",
    "        if reverse_target_token_index[prediction[:, i][0]] == \"<eop>\":\n",
    "            break\n",
    "        target_seq[:, i] = prediction[:, i]\n",
    "    decoded_sentence = []\n",
    "    for idx in target_seq[:, 1:][0]:\n",
    "        if idx == 0:\n",
    "            break\n",
    "        decoded_sentence.append(reverse_target_token_index[idx])\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [13:35<00:00,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted lists are saved to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove output file exists\n",
    "if os.path.exists(result_dir+\"testing_output.txt\"):\n",
    "    os.remove(result_dir+\"testing_output.txt\")\n",
    "# Test samples from the beginning of the testing dataset\n",
    "c = 1\n",
    "predicted_lists = []\n",
    "for seq_index in tqdm(range(n_input_samples_test)):\n",
    "    # Take one sequence (part of the training set) for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index:seq_index+1]\n",
    "    ###print('Input sentence: ' + test_do.input_texts[seq_index])\n",
    "    input_seq2 = encoder_input_data[seq_index]\n",
    "    input_list_tbp = []\n",
    "    for i, idx in enumerate(input_seq2):\n",
    "        if i == len(test_do.input_lists[seq_index]):\n",
    "            break\n",
    "        input_token = reverse_input_token_index[idx]\n",
    "        input_list_tbp.append(input_token)\n",
    "    to_print_out = ''\n",
    "    for token in input_list_tbp:\n",
    "        to_print_out += token + ' '\n",
    "    ###print('Encoded sentence:\\n' + to_print_out + '\\n')\n",
    "\n",
    "    ###print('Target sentence: ' + test_do.target_texts[seq_index])\n",
    "    decoded_sentence = decode_sequence(input_seq, generator, max_decoder_seq_length_train, target_token_index, reverse_target_token_index)\n",
    "    predicted_lists.append(decoded_sentence)\n",
    "    to_print_out2 = ''\n",
    "    for token in decoded_sentence:\n",
    "        to_print_out2 += token + ' '\n",
    "    ###print('Decoded sentence: ' + to_print_out)\n",
    "    ###print('-')\n",
    "\n",
    "    # Write output to file\n",
    "    with open(result_dir+\"testing_output.txt\", \"a\") as f:\n",
    "        f.write(str(c) + '.a) Input sentence:   ' + test_do.input_texts[seq_index] + \"\\n\")\n",
    "        f.write(str(c) + '.b) Encoded sentence: ' + to_print_out + \"\\n\")\n",
    "        f.write(str(c) + '.c) Target sentence:  ' + test_do.target_texts[seq_index] + \"\\n\")\n",
    "        f.write(str(c) + '.d) Decoded sentence: ' + to_print_out2 + \"\\n-\\n\")\n",
    "    c += 1\n",
    "\n",
    "# Save predicted lists to disk for result evaluation\n",
    "with open(result_dir+'predicted_lists.pkl', 'wb') as f:  \n",
    "    pickle.dump(predicted_lists, f)\n",
    "print('Predicted lists are saved to disk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
